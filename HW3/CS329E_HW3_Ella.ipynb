{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3\n",
    "\n",
    "## Pair Programming Group Number: FILL IN HERE\n",
    "## Members of Team: FILL IN HERE\n",
    "\n",
    "## Feature engineering and linear regression\n",
    "\n",
    "For this week's homework we are going to load in a data set that isn't in the \"cleanest\", repair it, add a feature, do some analysis on the features, build a linear regression model, and use that model to estimate numeric values.  Is linear regression _really_ machine learning? Depends on who you ask, but it is definitely an important tool for data analytics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only use these libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Load in the melb_data_sold_train.csv file here\n",
    "df = pd.read_csv('melb_data_sold_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 Fix the dataframe to remove any blanks\n",
    "The linear regression needs all attribute and dependent values to be defined.  Use list-wise deletion to remove entries with missing values. Save the modified dataframe with the indices reset to be $0-(length-1)$ into the variable `df1` for use in a later problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.dropna().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Add a new feature\n",
    "Toorak is known as one of the priciest suburbs in Melbourne.  Create a new column in your dataframe that is the distance in kilometers from the center of Toorak to the latitude/longitude of that row.  Use the latitude / longitude of $(-37.841820, 145.015986)$ for the center of Toorak.  You may assume the Earth is spherical and has radius of $6371.0088$km (check your function ... the property located at $(-37.68178,144.73779)$ is approx 30.2 km away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 : Define the Haversine distance as a function\n",
    "# assumes that pt1 and pt2 are 2x1 [lat,long] np arrays that contain locations of the 2 earth coordinates in deg\n",
    "# using the Haversine formula found https://en.wikipedia.org/wiki/Haversine_formula\n",
    "def haversine_distance(pt1,pt2):\n",
    "    lat1 = pt1[0]*np.pi/180\n",
    "    lat2 = pt2[0]*np.pi/180\n",
    "    lon1 = pt1[1]*np.pi/180\n",
    "    lon2 = pt2[1]*np.pi/180\n",
    "    havTheta = hav(lat2-lat1)+np.cos(lat1)*np.cos(lat2)*hav(lon2-lon1)\n",
    "    d_r = np.arccos(1-havTheta*2)\n",
    "    return d_r *6371.0088\n",
    "\n",
    "#code here, make sure pt1 and pt2 are passed in as degrees (lat,long) and convert to radians before calculation\n",
    "\n",
    "def hav(theta):\n",
    "    return (np.sin(theta/2))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.244772513599806"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick check to see if we are getting the expected value\n",
    "toorak_pt = np.array([-37.841820, 145.015986])\n",
    "haversine_distance(toorak_pt,[-37.68178,144.73779])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Date</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>distance_to_toorak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>25 Bloomburg St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>4/02/2016</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.80790</td>\n",
       "      <td>144.99340</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4.261612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>124 Yarra St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1876000.0</td>\n",
       "      <td>7/05/2016</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.80240</td>\n",
       "      <td>144.99930</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4.621843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>98 Charles St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1636000.0</td>\n",
       "      <td>8/10/2016</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>1890.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.80600</td>\n",
       "      <td>144.99540</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4.374206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>10 Valiant St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1097000.0</td>\n",
       "      <td>8/10/2016</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.80100</td>\n",
       "      <td>144.99890</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4.780655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>123/56 Nicholson St</td>\n",
       "      <td>2</td>\n",
       "      <td>u</td>\n",
       "      <td>750000.0</td>\n",
       "      <td>12/11/2016</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.80780</td>\n",
       "      <td>144.99650</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4.152012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3905</th>\n",
       "      <td>7985</td>\n",
       "      <td>Glenroy</td>\n",
       "      <td>69 Melbourne Av</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>680000.0</td>\n",
       "      <td>29/07/2017</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>422.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>Moreland</td>\n",
       "      <td>-37.70425</td>\n",
       "      <td>144.93164</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>16.998846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3906</th>\n",
       "      <td>7988</td>\n",
       "      <td>Greensborough</td>\n",
       "      <td>12 Yangoora Pl</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>900000.0</td>\n",
       "      <td>29/07/2017</td>\n",
       "      <td>3088.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>Banyule</td>\n",
       "      <td>-37.70077</td>\n",
       "      <td>145.12743</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>18.491623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3907</th>\n",
       "      <td>7995</td>\n",
       "      <td>Highett</td>\n",
       "      <td>1/12 Jillian Av</td>\n",
       "      <td>3</td>\n",
       "      <td>t</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>29/07/2017</td>\n",
       "      <td>3190.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>Bayside</td>\n",
       "      <td>-37.94775</td>\n",
       "      <td>145.02379</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>11.798784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3908</th>\n",
       "      <td>7997</td>\n",
       "      <td>Highett</td>\n",
       "      <td>31 The Crescent</td>\n",
       "      <td>4</td>\n",
       "      <td>t</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>29/07/2017</td>\n",
       "      <td>3190.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>Kingston</td>\n",
       "      <td>-37.94633</td>\n",
       "      <td>145.04947</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>11.986684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>7999</td>\n",
       "      <td>Hillside</td>\n",
       "      <td>20 Viridian Dr</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>618350.0</td>\n",
       "      <td>29/07/2017</td>\n",
       "      <td>3037.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>Melton</td>\n",
       "      <td>-37.68104</td>\n",
       "      <td>144.74608</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>29.708163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3910 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index         Suburb              Address  Rooms Type      Price  \\\n",
       "0         1     Abbotsford      25 Bloomburg St      2    h  1035000.0   \n",
       "1         3     Abbotsford         124 Yarra St      3    h  1876000.0   \n",
       "2         4     Abbotsford        98 Charles St      2    h  1636000.0   \n",
       "3         6     Abbotsford        10 Valiant St      2    h  1097000.0   \n",
       "4         7     Abbotsford  123/56 Nicholson St      2    u   750000.0   \n",
       "...     ...            ...                  ...    ...  ...        ...   \n",
       "3905   7985        Glenroy      69 Melbourne Av      3    h   680000.0   \n",
       "3906   7988  Greensborough       12 Yangoora Pl      4    h   900000.0   \n",
       "3907   7995        Highett      1/12 Jillian Av      3    t  1200000.0   \n",
       "3908   7997        Highett      31 The Crescent      4    t  1200000.0   \n",
       "3909   7999       Hillside       20 Viridian Dr      4    h   618350.0   \n",
       "\n",
       "            Date  Postcode  Bedroom2  Bathroom  Car  Landsize  BuildingArea  \\\n",
       "0      4/02/2016    3067.0       2.0       1.0  0.0     156.0          79.0   \n",
       "1      7/05/2016    3067.0       4.0       2.0  0.0     245.0         210.0   \n",
       "2      8/10/2016    3067.0       2.0       1.0  2.0     256.0         107.0   \n",
       "3      8/10/2016    3067.0       3.0       1.0  2.0     220.0          75.0   \n",
       "4     12/11/2016    3067.0       2.0       2.0  1.0       0.0          94.0   \n",
       "...          ...       ...       ...       ...  ...       ...           ...   \n",
       "3905  29/07/2017    3046.0       3.0       1.0  1.0     422.0         104.0   \n",
       "3906  29/07/2017    3088.0       4.0       3.0  1.0     807.0         190.0   \n",
       "3907  29/07/2017    3190.0       3.0       1.0  2.0     269.0         125.0   \n",
       "3908  29/07/2017    3190.0       4.0       2.0  2.0     304.0         183.0   \n",
       "3909  29/07/2017    3037.0       4.0       2.0  2.0     542.0         221.0   \n",
       "\n",
       "      YearBuilt CouncilArea  Lattitude  Longtitude             Regionname  \\\n",
       "0        1900.0       Yarra  -37.80790   144.99340  Northern Metropolitan   \n",
       "1        1910.0       Yarra  -37.80240   144.99930  Northern Metropolitan   \n",
       "2        1890.0       Yarra  -37.80600   144.99540  Northern Metropolitan   \n",
       "3        1900.0       Yarra  -37.80100   144.99890  Northern Metropolitan   \n",
       "4        2009.0       Yarra  -37.80780   144.99650  Northern Metropolitan   \n",
       "...         ...         ...        ...         ...                    ...   \n",
       "3905     1960.0    Moreland  -37.70425   144.93164  Northern Metropolitan   \n",
       "3906     1975.0     Banyule  -37.70077   145.12743  Northern Metropolitan   \n",
       "3907     2000.0     Bayside  -37.94775   145.02379  Southern Metropolitan   \n",
       "3908     2007.0    Kingston  -37.94633   145.04947  Southern Metropolitan   \n",
       "3909     2009.0      Melton  -37.68104   144.74608   Western Metropolitan   \n",
       "\n",
       "      distance_to_toorak  \n",
       "0               4.261612  \n",
       "1               4.621843  \n",
       "2               4.374206  \n",
       "3               4.780655  \n",
       "4               4.152012  \n",
       "...                  ...  \n",
       "3905           16.998846  \n",
       "3906           18.491623  \n",
       "3907           11.798784  \n",
       "3908           11.986684  \n",
       "3909           29.708163  \n",
       "\n",
       "[3910 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2 : Add a new column to `df1` called 'distance_to_toorak' that uses the haversine_distance function \n",
    "# to calculate the distance to Toorak for every row in our dataframe. Save the new dataframe as `df2`\n",
    "toorak_pt = np.array([-37.841820, 145.015986])\n",
    "df1[\"distance_to_toorak\"]=haversine_distance(toorak_pt ,np.array([df1[\"Lattitude\"],df1[\"Longtitude\"]]))\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 Create a one hot encoding for the categorical column 'Type'\n",
    "Modify the data frame `df2` such that it removes the column for `Type` and replaces it with the appropriate number of columns for a one-hot encoding of the column `Type` and save that dataframe as `df3` for use in a later problem. The pandas method [get_dummies](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) will be very useful here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2645\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2646\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-fa22160a2b6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mohe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mohe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mohe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mohe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#df3 = df2.insert(ind+i,str(i),ohe)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2798\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2799\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2800\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2647\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2648\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2650\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "df2 = df1.drop(\"Type\",1)\n",
    "ind = df1.columns.get_loc(\"Type\")\n",
    "ind\n",
    "ohe = pd.get_dummies(df1[\"Type\"],prefix = \"Type\",columns=\"Type\")\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for i in range(len(ohe.columns)):\n",
    "    df2.insert(ind+i,ohe.columns[i],ohe[i])\n",
    "    print(ohe[i])\n",
    "    #df3 = df2.insert(ind+i,str(i),ohe)\n",
    "df3\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 Calculate the pairwise correlations between all of your numeric attributes\n",
    "Use the Pearson correlation as discussed in the lectures to calculate the pairwise correlations between the attributes in the dataframe `df3`. Read the documentation for [corr](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 Create a linear regression model to predict home values\n",
    "Using the math in ESLII, section 3.2 equation (3.6) calculate $\\hat{\\beta}$\n",
    "\n",
    "We are going to create a linear regression model using our numeric attribute columns in `df3`, and specifying the home values (`Price` column) as the value we are trying to predict.  You may use numpy to do matrix calculations, but you may not use a built in regression library (for example, you may not use scikt-learn). \n",
    "\n",
    "The features you use to build the matrix $X$ should all be numeric and include the distance to Toorak and the one hot encodings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step one, build the matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step two, build the column vector y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step three, find beta hat per the formula (3.6) (you should use the library we used in class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model to see if we get something \"reasonable\" - i picked 23 at random \n",
    "np.matmul(X.iloc[23],beta_hat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the actual price at this point\n",
    "y[23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 Apply the linear regression model to the test data and visualize the error\n",
    "We will cover other methods of evaluating any sort of prediction later, but for this week's exercise I have partitioned the data into two files.  Load the melb_data_sold_test.csv data set and use the $\\hat{\\beta}$ you calculated in the last step to predict the housing prices for data in melb_data_sold_test.  Create a visualization that shows the absolute error in your predictions. Remember to do all your data pre-processing on the data loaded from the melb_data_sold_test file before you apply beta_hat.  For the visualization, a histogram of the absolute error vs the total housing prices is sufficient.  Use [hist](https://matplotlib.org/3.3.3/api/_as_gen/matplotlib.pyplot.hist.html) for reference. \n",
    "\n",
    "While doing imputation, there are some helpful parameters in [fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step zero, load the melb_data_sold_test.csv data for testing.  Use Imputation to fill in any missing numeric values\n",
    "# We use imputation here instead of deletion since we want a prediction for _every_ row in the test file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step one, add the new attribute for the 'distance_to_toorak' and the one hot encoding to the new data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step two, build the attribute matrix Xdot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step three, multiply Xdot by Beta hat. DO NOT USE A LOOP.  This is a vector of predicted prices\n",
    "# called y_hat in the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step four, calculate the error vector, |actual price - predicted price|. We call this our \"absolute error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step five, create a histogram of the absolute error, and on the same plot create a histogram of the actual price.  \n",
    "# You should use the \"alpha\" parameter to make the graph on top slightly translucent "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
